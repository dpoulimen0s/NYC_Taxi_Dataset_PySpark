{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7601bf0e-75f1-4b25-97f1-54e1d855bd12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# [CSC8101] Engineering for AI - 2024 Spark Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a451fe1b-c36e-4226-a708-a903f5844f7d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Coursework overview\n",
    "\n",
    "### Inputs\n",
    "\n",
    "- **NYC Taxi Trips dataset** - list of recorded taxi trips, each with several characteristics, namely: distance, number of passengers, origin zone, destination zone and trip cost (total amount charged to customer).\n",
    "- **NYC Zones dataset** - list of zones wherein trips can originate/terminate.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "1. Data cleaning\n",
    "  1. Remove \"0 distance\" and 'no passengers' records.\n",
    "  2. Remove outlier records. \n",
    "2. Add new columns\n",
    "  1. Join with zones dataset\n",
    "  2. Compute the unit profitability of each trip\n",
    "3. Zone summarisation and ranking\n",
    "  1. Summarise trip data per zone\n",
    "  2. Obtain the top 10 ranks according to:\n",
    "    1. The total trip volume\n",
    "    2. Their average profitabilitiy\n",
    "    3. The total passenger volume\n",
    "4. Record the total and task-specific execution times for each dataset size and format.\n",
    "\n",
    "### How to\n",
    "\n",
    "###### Code structure and implementation\n",
    "\n",
    "- You must implement your solution to each task in the provided function code skeleton.\n",
    "- The task-specific functions are combined together to form the full pipeline code, executed last (do not modify this code).\n",
    "- Before implementing the specified function skeleton, you should develop and test your solution on separate code cells (create and destroy cells as needed).\n",
    "\n",
    "###### Development\n",
    "\n",
    "- Develop an initial working solution for the 'S' dataset and only then optimise it for larger dataset sizes.\n",
    "- To perform vectorised operations on a DataFrame:\n",
    "  - use the API docs to look for existing vectorised functions in: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html\n",
    "  - actions to get around the lazy execution of spark: \n",
    "  https://spark.apache.org/docs/latest/rdd-programming-guide.html#actions\n",
    "  - if a customised function is required (e.g. to add a new column based on a linear combination of other columns), implement your own User Defined Function (UDF). See:  https://spark.apache.org/docs/latest/sql-ref-functions-udf-scalar.html\n",
    "- Use only the `pyspark.sql` API - documentation link below - (note that searching through the docs returns results from the `pyspark.sql` API together with the `pyspark.pandas` API):\n",
    "  - https://spark.apache.org/docs/3.2.0/api/python/reference/pyspark.sql.html\n",
    "- Periodically download your notebook to your computer as backup and safety measure against accidental file deletion.\n",
    " \n",
    "###### Execution time measurement\n",
    "\n",
    "- Execution time is calculated and returned by the Spark Engine and shown in the output region of the cell.\n",
    "- To measure the execution time of a task you must perform a `collect` or similar operation (e.g. `take`) on the returned DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d26c1c73-cac4-4937-8201-4c15cc6be296",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 0 - Read data\n",
    "\n",
    "The code below is ready to run. **Do not modify this code**. It does the following:\n",
    "\n",
    "- Reads the 'zones' dataset into variable 'zone_names'\n",
    "- Defines the `init_trips` function that allows you to read the 'trips' dataset (from the DBFS FileStore) given the dataset size ('S' to 'XXL') and format ('parquet' or 'delta') as function arguments\n",
    "- Defines the `pipeline` function, called in Task 4 to measure the execution time of the entire data processing pipeline\n",
    "- Shows you how to call the `init_trips` function and display dataset characteristics (number of rows, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57aaebcc-fc2a-4d86-a58e-c1489efeadaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## global imports\n",
    "import pyspark.sql as ps\n",
    "import pyspark.sql.functions as pf\n",
    "import pandas as pd\n",
    "\n",
    "# Load zone names dataset - (much faster to read small file from git than dbfs)\n",
    "zones_file_url = 'https://raw.githubusercontent.com/mutazb999/CSC8101-lab-and-coursework/main/02-assignment-spark/taxi_zone_names.csv'\n",
    "zone_names = spark.createDataFrame(pd.read_csv(zones_file_url))\n",
    "\n",
    "# Function to load trips dataset by selected dataset size\n",
    "def init_trips(size = 'S', data_format = \"parquet\", taxi_folder = \"/FileStore/tables/taxi\"):     \n",
    "    \n",
    "    files = {\n",
    "        'S'  : ['2021_07'],\n",
    "        'M'  : ['2021'],\n",
    "        'L'  : ['2020_21'],\n",
    "        'XL' : ['1_6_2019', '7_12_2019'],\n",
    "        'XXL': ['1_6_2019', '7_12_2019', '2020_21']\n",
    "    }\n",
    "    \n",
    "    # validate input dataset size\n",
    "    if size not in files.keys():\n",
    "        print(\"Invalid input dataset size. Must be one of {}\".format(list(files.keys())))\n",
    "        return None               \n",
    "    \n",
    "    if data_format == \"parquet\":\n",
    "        filenames = list(map(lambda s: f'{taxi_folder}/parquet/tripdata_{s}.parquet', files[size]))\n",
    "        trips_df = spark.read.parquet(filenames[0])\n",
    "        \n",
    "        for name in filenames[1:]:\n",
    "            trips_df = trips_df.union(spark.read.parquet(name))\n",
    "            \n",
    "    elif data_format == \"delta\":\n",
    "        filenames = f\"{taxi_folder}/delta/taxi-{size}-delta/\"\n",
    "        trips_df = spark.read.format(\"delta\").load(filenames)\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid data format. Must be one of {}\".format(['parquet', 'delta']))\n",
    "        return None\n",
    "        \n",
    "    print(\n",
    "    \"\"\"\n",
    "    Trips dataset loaded!\n",
    "    ---\n",
    "      Size: {s}\n",
    "      Format: {f}\n",
    "      Tables loaded: {ds}\n",
    "      Number of trips (dataset rows): {tc:,}\n",
    "    \"\"\".format(s = size, f = data_format, ds = filenames, tc = trips_df.count()))\n",
    "    \n",
    "    return trips_df\n",
    "\n",
    "# helper function to print dataset row count\n",
    "def print_count(df):\n",
    "    print(\"Row count: {t:,}\".format(t = df.count()))\n",
    "\n",
    "def pipeline(trips_df, with_task_12 = False, zones_df = zone_names):\n",
    "    # Do not edit\n",
    "    #---\n",
    "\n",
    "    ## Task 1.1\n",
    "    _trips_11 = t11_remove_zeros(trips_df)\n",
    "\n",
    "    ## Task 1.2\n",
    "    if with_task_12:\n",
    "        _trips_12 = t12_remove_outliers(_trips_11)\n",
    "    else:\n",
    "        _trips_12 = _trips_11\n",
    "\n",
    "    ## Task 2.1\n",
    "    _trips_21 = t21_join_zones(_trips_12, zones_df = zone_names)\n",
    "\n",
    "    ## Task 2.2\n",
    "    _trips_22 = t22_calc_profit(_trips_21)\n",
    "\n",
    "    ## Task 3.1\n",
    "    _graph = t31_summarise_trips(_trips_22)\n",
    "\n",
    "    ## Task 3.2\n",
    "    _zones = t32_summarise_zones_pairs(_graph)\n",
    "\n",
    "    _top10_trips     = t32_top10_trips(_zones)\n",
    "    _top10_profit    = t32_top10_profit(_zones)\n",
    "    _top10_passenger = t32_top10_passenger(_zones)\n",
    "    \n",
    "    return([_top10_trips, _top10_profit, _top10_passenger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "490ab841-fd73-4466-a6e7-5121395deca9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n    Trips dataset loaded!\n    ---\n      Size: S\n      Format: parquet\n      Tables loaded: ['/FileStore/tables/taxi/parquet/tripdata_2021_07.parquet']\n      Number of trips (dataset rows): 2,898,033\n    \n"
     ]
    }
   ],
   "source": [
    "# CHANGE the value of argument 'size' to record the pipeline execution times for increasing dataset sizes\n",
    "SIZE = 'S'\n",
    "DATA_FORMAT = 'parquet'\n",
    "\n",
    "# Load trips dataset\n",
    "trips = init_trips(SIZE, DATA_FORMAT)\n",
    "\n",
    "# uncomment line only for small datasets\n",
    "# trips.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92da0d12-33a0-4df0-b1d2-607ebb65d948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 2,898,033\n"
     ]
    }
   ],
   "source": [
    "print_count(trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "490e67f7-4457-4bd5-b89a-a6d24c5645d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- index: long (nullable = true)\n |-- VendorID: double (nullable = true)\n |-- tpep_pickup_datetime: string (nullable = true)\n |-- tpep_dropoff_datetime: string (nullable = true)\n |-- passenger_count: double (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- RatecodeID: double (nullable = true)\n |-- store_and_fwd_flag: string (nullable = true)\n |-- PULocationID: long (nullable = true)\n |-- DOLocationID: long (nullable = true)\n |-- payment_type: double (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- extra: double (nullable = true)\n |-- mta_tax: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- tolls_amount: double (nullable = true)\n |-- improvement_surcharge: double (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- congestion_surcharge: double (nullable = true)\n |-- cab_type: string (nullable = true)\n |-- lpep_pickup_datetime: string (nullable = true)\n |-- lpep_dropoff_datetime: string (nullable = true)\n |-- ehail_fee: double (nullable = true)\n |-- trip_type: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# dataset schemas\n",
    "trips.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e2ab160-b9b8-4c4a-bb70-fc3197bae230",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PULocationID</th><th>DOLocationID</th><th>trip_distance</th><th>passenger_count</th><th>total_amount</th></tr></thead><tbody><tr><td>90</td><td>68</td><td>0.8</td><td>1.0</td><td>8.8</td></tr><tr><td>113</td><td>90</td><td>0.9</td><td>1.0</td><td>8.8</td></tr><tr><td>88</td><td>232</td><td>2.8</td><td>1.0</td><td>13.8</td></tr><tr><td>79</td><td>249</td><td>1.4</td><td>1.0</td><td>12.3</td></tr><tr><td>142</td><td>238</td><td>2.0</td><td>0.0</td><td>12.3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         90,
         68,
         0.8,
         1.0,
         8.8
        ],
        [
         113,
         90,
         0.9,
         1.0,
         8.8
        ],
        [
         88,
         232,
         2.8,
         1.0,
         13.8
        ],
        [
         79,
         249,
         1.4,
         1.0,
         12.3
        ],
        [
         142,
         238,
         2.0,
         0.0,
         12.3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PULocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "DOLocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "trip_distance",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "passenger_count",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_amount",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trips[['PULocationID', 'DOLocationID', 'trip_distance', 'passenger_count', 'total_amount']].take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee4451c-b49a-42a6-b87e-81aad4144cf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- LocationID: long (nullable = true)\n |-- Borough: string (nullable = true)\n |-- Zone: string (nullable = true)\n |-- service_zone: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "zone_names.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a1ed0a0-0621-471d-8332-d47b52f71817",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr></thead><tbody><tr><td>1</td><td>EWR</td><td>Newark Airport</td><td>EWR</td></tr><tr><td>2</td><td>Queens</td><td>Jamaica Bay</td><td>Boro Zone</td></tr><tr><td>3</td><td>Bronx</td><td>Allerton/Pelham Gardens</td><td>Boro Zone</td></tr><tr><td>4</td><td>Manhattan</td><td>Alphabet City</td><td>Yellow Zone</td></tr><tr><td>5</td><td>Staten Island</td><td>Arden Heights</td><td>Boro Zone</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "EWR",
         "Newark Airport",
         "EWR"
        ],
        [
         2,
         "Queens",
         "Jamaica Bay",
         "Boro Zone"
        ],
        [
         3,
         "Bronx",
         "Allerton/Pelham Gardens",
         "Boro Zone"
        ],
        [
         4,
         "Manhattan",
         "Alphabet City",
         "Yellow Zone"
        ],
        [
         5,
         "Staten Island",
         "Arden Heights",
         "Boro Zone"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "LocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Borough",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Zone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "service_zone",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(zone_names.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99294dd5-92b7-4e50-9623-d00d82da993b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 1 - Filter rows\n",
    "\n",
    "**Input:** trips dataset\n",
    "\n",
    "### Task 1.1 - Remove \"0 distance\" and 'no passengers' records\n",
    "\n",
    "Remove dataset rows that represent invalid trips:\n",
    "\n",
    "- Trips where `trip_distance == 0` (no distance travelled)\n",
    "- Trips where `passenger_count == 0` and `total_amount == 0` (we want to retain records where `total_amount` > 0 - these may be significant as the taxi may have carried some parcel, for example)\n",
    "\n",
    "Altogether, a record is removed if it satisfies the following conditions:\n",
    "\n",
    "`trip_distance == 0` or `(passenger_count == 0` and `total_amount == 0)`.\n",
    "\n",
    "**Recommended:** Select only the relevant dataset columns for this and subsequent tasks: `['PULocationID', 'DOLocationID', 'trip_distance', 'passenger_count', 'total_amount')]`\n",
    "\n",
    "### Task 1.2 - Remove outliers using the modified z-score\n",
    "\n",
    "Despite having removed spurious \"zero passengers\" trips in task 1.1, columns `total_amount` and `trip_distance` contain additional outlier values that must be identified and removed.\n",
    "\n",
    "To identify and remove outliers, you will use the modified [z-score](https://en.wikipedia.org/wiki/Standard_score) method.\n",
    "The modified z-score uses the median and [Median Absolute Deviation](https://en.wikipedia.org/wiki/Median_absolute_deviation) (MAD), instead of the mean and standard deviation, to determine how far an observation (indexed by i) is from the mean:\n",
    "\n",
    "$$z_i = \\frac{x_i - \\mathit{median}(\\mathbf{x})}{\\mathbf{MAD}},$$\n",
    "\n",
    "where x represents the input vector, xi is an element of x and zi is its corresponding z-score. In turn, the MAD formula is:\n",
    "\n",
    "$$\\mathbf{MAD} = 1.483 * \\mathit{median}(\\big\\lvert x_i - \\mathit{median}(\\mathbf{x})\\big\\rvert).$$\n",
    "\n",
    "Observations with **high** (absolute) z-score are considered outlier observations. A score is considered **high** if its __absolute z-score__ is larger than a threshold T = 3.5:\n",
    "\n",
    "$$\\big\\lvert z_i \\big\\rvert > 3.5.$$\n",
    "\n",
    "where T represents the number of unit standard deviations beyond which a score is considered an outlier ([wiki](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule)).\n",
    "\n",
    "This process is repeated twice, once for each of the columns `total_amount` and `trip_distance` (in any order).\n",
    "\n",
    "**Important:** Use the surrogate function [`percentile_approx`](https://spark.apache.org/docs/3.2.0/api/python/reference/api/pyspark.sql.functions.percentile_approx.html?highlight=percentile#pyspark.sql.functions.percentile_approx) to estimate the median (calculating the median values for a column is expensive as it cannot be parallelised efficiently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b53021ef-a0ab-43be-8885-142617707a5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# develop your solution here (create/destroy cells as needed) and then implement it in the functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ac2d5d7-21d4-4bbb-b2ea-0e6e4df89a58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Your solution implementation to task 1.1 goes HERE\n",
    "\n",
    "# Logic\n",
    "# Trip Distance Check: The condition col(\"trip_distance\") != 0 ensures that we exclude trips where the recorded distance is zero. Trips with zero distance are either data errors or represent trips that were booked but not actually taken.\n",
    "\n",
    "# Passenger Count and Total Amount Check: The condition ~((col(\"passenger_count\") == 0) & (col(\"total_amount\") == 0)) serves to remove records where there were no passengers (passenger_count == 0) and no charge (total_amount == 0). However, it's important to retain records where total_amount > 0 even if passenger_count == 0, as these might represent valid scenarios like parcel deliveries.\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def t11_remove_zeros(df):\n",
    "    # Filter out rows where trip distance is 0 or both passenger count and total amount are 0\n",
    "    return df.filter((col(\"trip_distance\") != 0) & ~((col(\"passenger_count\") == 0) & (col(\"total_amount\") == 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c6c287d-8707-4989-8ee9-2967a486c925",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 2,858,164\n"
     ]
    }
   ],
   "source": [
    "# execute task 1.1\n",
    "trips_11 = t11_remove_zeros(trips)\n",
    "\n",
    "print_count(trips_11)\n",
    "\n",
    "## uncomment only for smaller datasets\n",
    "# display(trips_11.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0162cd3-d060-495d-9a86-ebf4a6f507ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Your solution implementation to task 1.2 goes HERE\n",
    "\n",
    "# Logic\n",
    "\n",
    "# Median and MAD Calculation:\n",
    "# The nested function calculate_mad computes the Median Absolute Deviation (MAD) for a specified column. MAD is a measure of variability that is more robust to outliers than standard deviation.\n",
    "# The median and MAD are calculated for the total_amount and trip_distance columns. The MAD is scaled by a factor of 1.483 to make it consistent with the standard deviation for a normal distribution (This number was given in the instructions).\n",
    "\n",
    "# Modified Z-Score Calculation:\n",
    "# The modified Z-score for each data point in the specified columns is calculated. It measures how far (in terms of MAD) a data point is from the median.\n",
    "\n",
    "# Filtering Outliers:\n",
    "# Data points with an absolute modified Z-score greater than the threshold (3.5 in this case) are considered outliers and are filtered out.\n",
    "# The threshold of 3.5 is a typical choice for identifying outliers.\n",
    "\n",
    "from pyspark.sql.functions import abs\n",
    "\n",
    "def t12_remove_outliers(df):\n",
    "    \n",
    "    def calculate_mad(df, column_name):\n",
    "        # Calculate the median of the specified column\n",
    "        median = df.approxQuantile(column_name, [0.5], 0.01)[0]\n",
    "\n",
    "        # Calculate the MAD and apply scaling factor\n",
    "        mad = df.withColumn('abs_diff', abs(col(column_name) - median)) \\\n",
    "                .approxQuantile('abs_diff', [0.5], 0.01)[0]\n",
    "        mad_scaled = 1.483 * mad  # Apply the scaling factor\n",
    "        return median, mad_scaled\n",
    "\n",
    "    # Define the threshold for the modified Z-score\n",
    "    threshold = 3.5\n",
    "\n",
    "    # Iterate over each column to remove outliers\n",
    "    for column in ['total_amount', 'trip_distance']:\n",
    "        # Calculate median and scaled MAD for the column\n",
    "        median, mad_scaled = calculate_mad(df, column)\n",
    "\n",
    "        # Calculate modified Z-Score and filter the DataFrame\n",
    "        z_score_expr = (col(column) - median) / mad_scaled\n",
    "        df = df.filter(abs(z_score_expr) <= threshold)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96533a0e-242b-42d6-bc10-3b1ea3a13681",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 2,435,246\n"
     ]
    }
   ],
   "source": [
    "# execute task 1.2\n",
    "trips_12 = t12_remove_outliers(trips_11)\n",
    "\n",
    "print_count(trips_12)\n",
    "# display(trips_12.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77f3f561-5d39-46bf-84fa-0b0c3aafa0cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 2 - Compute new columns\n",
    "\n",
    "### Task 2.1 - Zone names\n",
    "\n",
    "Obtain the **start** and **end** zone names of each trip by joining the `trips` and `zone_names` datasets (i.e. by using the `zone_names` dataset as lookup table).\n",
    "\n",
    "**Note:** The columns containing the start and end zone ids of each trip are named `PULocationID` and `DOLocationID`, respectively.\n",
    "\n",
    "### Task 2.2 - Unit profitability\n",
    "\n",
    "Compute the column `unit_profitability = total_amount / trip_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a61d8288-1539-4f34-856f-98aa7fd0f7f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- index: long (nullable = true)\n |-- VendorID: double (nullable = true)\n |-- tpep_pickup_datetime: string (nullable = true)\n |-- tpep_dropoff_datetime: string (nullable = true)\n |-- passenger_count: double (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- RatecodeID: double (nullable = true)\n |-- store_and_fwd_flag: string (nullable = true)\n |-- PULocationID: long (nullable = true)\n |-- DOLocationID: long (nullable = true)\n |-- payment_type: double (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- extra: double (nullable = true)\n |-- mta_tax: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- tolls_amount: double (nullable = true)\n |-- improvement_surcharge: double (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- congestion_surcharge: double (nullable = true)\n |-- cab_type: string (nullable = true)\n |-- lpep_pickup_datetime: string (nullable = true)\n |-- lpep_dropoff_datetime: string (nullable = true)\n |-- ehail_fee: double (nullable = true)\n |-- trip_type: double (nullable = true)\n\nroot\n |-- LocationID: long (nullable = true)\n |-- Borough: string (nullable = true)\n |-- Zone: string (nullable = true)\n |-- service_zone: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# develop your solution here (create/destroy cells as needed) and then implement it in the functions below\n",
    "# Review the schema of the trips DataFrame\n",
    "trips_12.printSchema()\n",
    "\n",
    "# Review the schema of the zone_names DataFrame\n",
    "zone_names.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf0cd0ff-8d0a-4b46-82de-e2edd56e2f10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Your solution implementation to task 2.1 goes HERE\n",
    "\n",
    "# Logic \n",
    "\n",
    "# Initial Join for Pickup Locations:\n",
    "# The trips dataset (trips_df) is joined with the zone names dataset (zones_df) on the PULocationID column. This join operation maps each pickup location ID to its corresponding zone name.\n",
    "# The Zone and Borough columns from zones_df are renamed to PUZone and PUBorough respectively, to explicitly indicate that these refer to the pickup locations. The join is a left join, ensuring that all records in trips_df are retained, even if no matching zone name is found.\n",
    "\n",
    "#Subsequent Join for Dropoff Locations:\n",
    "# A second join is performed on the result of the first join, this time using the DOLocationID column. This associates each dropoff location ID with its zone name.\n",
    "# Again, the Zone and Borough columns are renamed, now to DOZone and DOBorough, to denote dropoff locations. As with the first join, a left join is used to maintain all trip records.\n",
    "\n",
    "# Handling Duplicate Columns:\n",
    "# After each join, the function drops the LocationID and service_zone columns that come from zones_df to avoid duplicate and unnecessary information in the resulting DataFrame.\n",
    "\n",
    "def t21_join_zones(trips_df, zones_df=zone_names):\n",
    "    # Perform the join for pickup locations\n",
    "    trips_with_pu = trips_df.join(zones_df, trips_df.PULocationID == zones_df.LocationID, \"left\") \\\n",
    "                            .withColumnRenamed(\"Zone\", \"PUZone\") \\\n",
    "                            .withColumnRenamed(\"Borough\", \"PUBorough\") \\\n",
    "                            .drop(\"LocationID\", \"service_zone\")  # Drop duplicate columns after join\n",
    "\n",
    "    # Perform the join for dropoff locations\n",
    "    trips_with_pu_do = trips_with_pu.join(zones_df, trips_with_pu.DOLocationID == zones_df.LocationID, \"left\") \\\n",
    "                                    .withColumnRenamed(\"Zone\", \"DOZone\") \\\n",
    "                                    .withColumnRenamed(\"Borough\", \"DOBorough\") \\\n",
    "                                    .drop(\"LocationID\", \"service_zone\")  # Drop duplicate columns after join\n",
    "\n",
    "    return trips_with_pu_do\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a3abc15-94bb-4352-964f-e3919956b363",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 2,435,246\n"
     ]
    }
   ],
   "source": [
    "# execute task 2.1\n",
    "trips_21 = t21_join_zones(trips_12, zones_df = zone_names)\n",
    "\n",
    "print_count(trips_21)\n",
    "#display(trips_21.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "244ecaed-2632-4ed1-ab91-e41d8a91b7c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Your solution implementation to task 2.2 goes HERE\n",
    "\n",
    "# Logic\n",
    "\n",
    "# The logic behind this is that the  unit profitability is calculated as the ratio of total_amount to trip_distance. This ratio represents the average amount of money earned per unit of distance traveled. The formula has been given to us in the instructions therefore the implementation is straightforward.\n",
    "\n",
    "def t22_calc_profit(df):\n",
    "    # Add the new column 'unit_profitability'\n",
    "    df = df.withColumn(\"unit_profitability\", col(\"total_amount\") / col(\"trip_distance\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3528be7-4fe2-4e68-a94b-a3b33ada952c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 2,435,246\n"
     ]
    }
   ],
   "source": [
    "# execute task 2.2\n",
    "trips_22 = t22_calc_profit(trips_21)\n",
    "\n",
    "print_count(trips_22)\n",
    "# display(trips_22.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5323bd8b-c18c-4ab9-be03-a38a94fb12a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+--------+--------------------+---------------------+---------+---------+---------+--------------------+---------+--------------------+------------------+\n|index|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|cab_type|lpep_pickup_datetime|lpep_dropoff_datetime|ehail_fee|trip_type|PUBorough|              PUZone|DOBorough|              DOZone|unit_profitability|\n+-----+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+--------+--------------------+---------------------+---------+---------+---------+--------------------+---------+--------------------+------------------+\n|    0|     1.0| 2021-07-01 00:08:51|  2021-07-01 00:13:05|            1.0|          0.8|       1.0|                 N|          90|          68|         1.0|        5.0|  3.0|    0.5|       0.0|         0.0|                  0.3|         8.8|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|            Flatiron|Manhattan|        East Chelsea|              11.0|\n|    1|     1.0| 2021-07-01 00:22:39|  2021-07-01 00:25:58|            1.0|          0.9|       1.0|                 N|         113|          90|         2.0|        5.0|  3.0|    0.5|       0.0|         0.0|                  0.3|         8.8|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|Greenwich Village...|Manhattan|            Flatiron| 9.777777777777779|\n|    2|     1.0| 2021-07-01 00:48:33|  2021-07-01 00:54:58|            1.0|          2.8|       1.0|                 N|          88|         232|         2.0|       10.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.8|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|Financial Distric...|Manhattan|Two Bridges/Sewar...| 4.928571428571429|\n|    3|     1.0| 2021-07-01 00:59:44|  2021-07-01 01:07:09|            1.0|          1.4|       1.0|                 N|          79|         249|         1.0|        7.0|  3.0|    0.5|       1.5|         0.0|                  0.3|        12.3|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|        East Village|Manhattan|        West Village| 8.785714285714286|\n|    4|     1.0| 2021-07-01 00:08:35|  2021-07-01 00:16:28|            0.0|          2.0|       1.0|                 N|         142|         238|         1.0|        8.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.3|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan| Lincoln Square East|Manhattan|Upper West Side N...|              6.15|\n|    5|     1.0| 2021-07-01 00:10:49|  2021-07-01 00:18:42|            1.0|          1.6|       1.0|                 N|         114|          90|         1.0|        7.5|  3.0|    0.5|       1.5|         0.0|                  0.3|        12.8|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|Greenwich Village...|Manhattan|            Flatiron|               8.0|\n|    6|     1.0| 2021-07-01 00:28:56|  2021-07-01 00:36:11|            1.0|          1.8|       1.0|                 N|          90|         144|         1.0|        7.5|  3.0|    0.5|       2.0|         0.0|                  0.3|        13.3|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|            Flatiron|Manhattan| Little Italy/NoLiTa| 7.388888888888889|\n|    7|     1.0| 2021-07-01 00:45:10|  2021-07-01 00:52:46|            1.0|          2.0|       1.0|                 N|         114|          48|         1.0|        8.5|  3.0|    0.5|      2.45|         0.0|                  0.3|       14.75|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|Greenwich Village...|Manhattan|        Clinton East|             7.375|\n|    8|     1.0| 2021-07-01 00:55:43|  2021-07-01 01:10:56|            1.0|          5.7|       1.0|                 N|          48|         152|         2.0|       18.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        22.3|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|        Clinton East|Manhattan|      Manhattanville| 3.912280701754386|\n|    9|     1.0| 2021-07-01 00:04:24|  2021-07-01 00:13:23|            1.0|          1.8|       1.0|                 N|         234|         148|         1.0|        8.5|  3.0|    0.5|      2.45|         0.0|                  0.3|       14.75|                 2.5|       Y|                NULL|                 NULL|     NULL|     NULL|Manhattan|            Union Sq|Manhattan|     Lower East Side| 8.194444444444445|\n+-----+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+--------+--------------------+---------------------+---------+---------+---------+--------------------+---------+--------------------+------------------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 rows of the DataFrame\n",
    "trips_22.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93c4a6e7-512f-40a8-ad2c-41a84ade373f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 3: Rank zones by traffic, passenger volume and profitability\n",
    "\n",
    "### 3.1 - Summarise interzonal travel\n",
    "\n",
    "Build a graph data structure of zone-to-zone traffic, representing aggregated data about trips between any two zones. The graph will have one node for each zone and one edge connecting each pair of zones. In addition, edges contain aggregate information about all trips between those zones. \n",
    "\n",
    "For example, zones Z1 and Z2 are connected by *two* edges: edge Z1 --> Z2 carries aggregate data about all trips that originated in Z1 and ended in Z2, and edge Z2 --> Z1 carries aggregate data about all trips that originated in Z2 and ended in Z1.\n",
    "\n",
    "The aggregate information of interzonal travel must include the following data:\n",
    "\n",
    "- `average_unit_profit` - the average unit profitability (calculated as `mean(unit_profitability)`).\n",
    "- `trips_count` -- the total number of recorded trips.\n",
    "- `total_passengers` -- the total number of passenger across all trips (sum of `passenger_count`).\n",
    "\n",
    "This graph can be represented as a new dataframe, with schema:\n",
    "\n",
    "\\[`PULocationID`, `DOLocationID`, `average_unit_profit`, `trips_count`, `total_passengers` \\]\n",
    "\n",
    "__hint__: the `groupby()` operator produces a `pyspark.sql.GroupedData` structure. You can then calculate multiple aggregations from this using `pyspark.sql.GroupedData.agg()`: \n",
    "- https://spark.apache.org/docs/3.2.0/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.groupby.html\n",
    "- https://spark.apache.org/docs/3.2.0/api/python/reference/api/pyspark.sql.GroupedData.agg.html\n",
    "\n",
    "### Task 3.2 - Obtain top-10 zones\n",
    "\n",
    "For each of the following measures, report the top-10 zones _using their plain names you dereferenced in the previous step, not the codes_. Note that this requires ranking the nodes in different orders. Specifically, you need to calculate the following further aggregations:\n",
    "\n",
    "- the **total** number of trips originating from Z. This is simply the sum of `trips_count` over all outgoing edges for Z, i.e., edges of the form Z -> \\*\n",
    "- the **average** profitability of a zone. This is the average of all `average_unit_profit` over all *outgoing* edges from Z.\n",
    "- The **total** passenger volume measured as the **sum** of `total_passengers` carried in trips that originate from Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "069fc68b-acdd-47c2-be12-27d32b7916c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# develop your solution here (create/destroy cells as needed) and then implement it in the functions below\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38084194-2635-46aa-ac74-93509c03a86e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Your solution to task 3.1 goes HERE\n",
    "\n",
    "# Logic\n",
    "\n",
    "# Grouping by Pickup and Dropoff Locations:\n",
    "# The function groups the data by PULocationID and DOLocationID. Each group represents a unique pair of zones, corresponding to the start and end points of trips.\n",
    "# This grouping effectively creates the edges of the graph, where each edge connects a pickup location (node) to a dropoff location (node).\n",
    "\n",
    "# Aggregating Key Metrics:\n",
    "# For each pair of zones, the following metrics are aggregated:\n",
    "    # F.mean(\"unit_profitability\").alias(\"average_unit_profit\"): Calculates the average unit profitability of trips between each pair of zones. This metric helps understand the financial efficiency of trips on each route.\n",
    "    # F.count(\"*\").alias(\"trips_count\"): Counts the total number of trips that occurred between each pair of zones. This gives an idea of the traffic volume or popularity of each route.\n",
    "    # F.sum(\"passenger_count\").alias(\"total_passengers\"): Sums the total number of passengers for all trips between each pair of zones. This indicates the overall passenger load on each route.\n",
    "\n",
    "# Resulting DataFrame - graph_df:\n",
    "# The resulting DataFrame graph_df contains columns for PULocationID, DOLocationID, average_unit_profit, trips_count, and total_passengers.\n",
    "# Each row in graph_df provides a comprehensive snapshot of the traffic, financial efficiency, and passenger volume for trips between each unique pair of zones.\n",
    "\n",
    "def t31_summarise_trips(df):\n",
    "    # Aggregate data for trips between zones\n",
    "    graph_df = df.groupBy(\"PULocationID\", \"DOLocationID\").agg(\n",
    "        F.mean(\"unit_profitability\").alias(\"average_unit_profit\"),\n",
    "        F.count(\"*\").alias(\"trips_count\"),\n",
    "        F.sum(\"passenger_count\").alias(\"total_passengers\")\n",
    "    )\n",
    "\n",
    "    return graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b81c74ad-e5f1-4b69-a320-bdf375b94e8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 11,833\n"
     ]
    }
   ],
   "source": [
    "# execute task 3.1\n",
    "graph = t31_summarise_trips(trips_22)\n",
    "\n",
    "print_count(graph)\n",
    "# display(graph.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22291ab8-431b-4c91-998e-e7c4aea049df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PULocationID</th><th>DOLocationID</th><th>average_unit_profit</th><th>trips_count</th><th>total_passengers</th></tr></thead><tbody><tr><td>228</td><td>26</td><td>7.41471058428216</td><td>8</td><td>2.0</td></tr><tr><td>108</td><td>26</td><td>6.236111111111111</td><td>1</td><td>1.0</td></tr><tr><td>25</td><td>26</td><td>4.722645989088705</td><td>2</td><td>3.0</td></tr><tr><td>21</td><td>29</td><td>8.13479934900303</td><td>9</td><td>1.0</td></tr><tr><td>97</td><td>26</td><td>4.504891363110619</td><td>9</td><td>10.0</td></tr><tr><td>22</td><td>26</td><td>15.249447857883409</td><td>32</td><td>2.0</td></tr><tr><td>178</td><td>26</td><td>9.437984319433491</td><td>9</td><td>3.0</td></tr><tr><td>26</td><td>26</td><td>19.89301966792171</td><td>86</td><td>11.0</td></tr><tr><td>181</td><td>26</td><td>6.467595978916211</td><td>11</td><td>6.0</td></tr><tr><td>87</td><td>29</td><td>6.241486068111455</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         228,
         26,
         7.41471058428216,
         8,
         2.0
        ],
        [
         108,
         26,
         6.236111111111111,
         1,
         1.0
        ],
        [
         25,
         26,
         4.722645989088705,
         2,
         3.0
        ],
        [
         21,
         29,
         8.13479934900303,
         9,
         1.0
        ],
        [
         97,
         26,
         4.504891363110619,
         9,
         10.0
        ],
        [
         22,
         26,
         15.249447857883409,
         32,
         2.0
        ],
        [
         178,
         26,
         9.437984319433491,
         9,
         3.0
        ],
        [
         26,
         26,
         19.89301966792171,
         86,
         11.0
        ],
        [
         181,
         26,
         6.467595978916211,
         11,
         6.0
        ],
        [
         87,
         29,
         6.241486068111455,
         1,
         1.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PULocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "DOLocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "average_unit_profit",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "trips_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_passengers",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(graph.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c285cd2d-861b-4790-8fe8-4b4b6cdbc8f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Your solution to task 3.2 goes HERE (implement each of the functions below)\n",
    "\n",
    "# Logic \n",
    "\n",
    "# Function t32_summarise_zones_pairs:\n",
    "# Currently, this function simply returns the input DataFrame df. If additional summarization or processing is required, it should be implemented here. Otherwise, this function may not be necessary.\n",
    "\n",
    "# Function t32_top10_trips (Top 10 Zones by Trip Volume):\n",
    "# Aggregates the total number of trips originating from each zone (PULocationID).\n",
    "# Ranks the zones by the aggregated total_trips in descending order and selects the top 10.\n",
    "# Joins the resulting DataFrame with zone_names to associate each PULocationID with its readable zone name.\n",
    "\n",
    "# Function t32_top10_profit (Top 10 Zones by Profit):\n",
    "# Calculates the average profitability (average_unit_profit) for each originating zone.\n",
    "# Orders the zones by average_profit in descending order and picks the top 10.\n",
    "# Joins the resulting DataFrame with zone_names for readable zone names.\n",
    "\n",
    "# Function t32_top10_passenger (Top 10 Zones by Passenger Volume):\n",
    "# Aggregates the total passenger volume (total_passengers) for each originating zone.\n",
    "# Sorts the zones by total_passengers in descending order and selects the top 10.\n",
    "# Performs a join with zone_names to get the readable names of the zones.\n",
    "\n",
    "def t32_summarise_zones_pairs(df, zones_df = zone_names):\n",
    "    return df\n",
    "\n",
    "# Top 10 ranked zones by traffic (trip volume)\n",
    "def t32_top10_trips(df_zones):\n",
    "    top_zones_by_trips = df_zones.groupBy(\"PULocationID\").agg(\n",
    "        F.sum(\"trips_count\").alias(\"total_trips\")\n",
    "    ).orderBy(F.desc(\"total_trips\")).limit(10)\n",
    "\n",
    "    return top_zones_by_trips.join(zone_names, top_zones_by_trips.PULocationID == zone_names.LocationID, \"left\")\n",
    "\n",
    "\n",
    "# Top 10 ranked zones by profit\n",
    "def t32_top10_profit(df_zones):\n",
    "    top_zones_by_profit = df_zones.groupBy(\"PULocationID\").agg(\n",
    "        F.mean(\"average_unit_profit\").alias(\"average_profit\")\n",
    "    ).orderBy(F.desc(\"average_profit\")).limit(10)\n",
    "\n",
    "    return top_zones_by_profit.join(zone_names, top_zones_by_profit.PULocationID == zone_names.LocationID, \"left\")\n",
    "\n",
    "\n",
    "# Top 10 ranked zones by passenger volume\n",
    "def t32_top10_passenger(df_zones):\n",
    "    top_zones_by_passengers = df_zones.groupBy(\"PULocationID\").agg(\n",
    "        F.sum(\"total_passengers\").alias(\"total_passengers\")\n",
    "    ).orderBy(F.desc(\"total_passengers\")).limit(10)\n",
    "\n",
    "    return top_zones_by_passengers.join(zone_names, top_zones_by_passengers.PULocationID == zone_names.LocationID, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb32624-cca2-461e-816d-c49ecc98374e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# execute task 3.2\n",
    "zones = t32_summarise_zones_pairs(graph)\n",
    "\n",
    "top10_trips     = t32_top10_trips(zones)\n",
    "top10_profit    = t32_top10_profit(zones)\n",
    "top10_passenger = t32_top10_passenger(zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "382adcca-e15c-45d2-88bf-6ae97b8c6e30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PULocationID</th><th>total_trips</th><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr></thead><tbody><tr><td>48</td><td>73585</td><td>48</td><td>Manhattan</td><td>Clinton East</td><td>Yellow Zone</td></tr><tr><td>141</td><td>73531</td><td>141</td><td>Manhattan</td><td>Lenox Hill West</td><td>Yellow Zone</td></tr><tr><td>142</td><td>80200</td><td>142</td><td>Manhattan</td><td>Lincoln Square East</td><td>Yellow Zone</td></tr><tr><td>161</td><td>92794</td><td>161</td><td>Manhattan</td><td>Midtown Center</td><td>Yellow Zone</td></tr><tr><td>162</td><td>84103</td><td>162</td><td>Manhattan</td><td>Midtown East</td><td>Yellow Zone</td></tr><tr><td>170</td><td>87410</td><td>170</td><td>Manhattan</td><td>Murray Hill</td><td>Yellow Zone</td></tr><tr><td>186</td><td>95864</td><td>186</td><td>Manhattan</td><td>Penn Station/Madison Sq West</td><td>Yellow Zone</td></tr><tr><td>236</td><td>102930</td><td>236</td><td>Manhattan</td><td>Upper East Side North</td><td>Yellow Zone</td></tr><tr><td>237</td><td>121281</td><td>237</td><td>Manhattan</td><td>Upper East Side South</td><td>Yellow Zone</td></tr><tr><td>239</td><td>73739</td><td>239</td><td>Manhattan</td><td>Upper West Side South</td><td>Yellow Zone</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         48,
         73585,
         48,
         "Manhattan",
         "Clinton East",
         "Yellow Zone"
        ],
        [
         141,
         73531,
         141,
         "Manhattan",
         "Lenox Hill West",
         "Yellow Zone"
        ],
        [
         142,
         80200,
         142,
         "Manhattan",
         "Lincoln Square East",
         "Yellow Zone"
        ],
        [
         161,
         92794,
         161,
         "Manhattan",
         "Midtown Center",
         "Yellow Zone"
        ],
        [
         162,
         84103,
         162,
         "Manhattan",
         "Midtown East",
         "Yellow Zone"
        ],
        [
         170,
         87410,
         170,
         "Manhattan",
         "Murray Hill",
         "Yellow Zone"
        ],
        [
         186,
         95864,
         186,
         "Manhattan",
         "Penn Station/Madison Sq West",
         "Yellow Zone"
        ],
        [
         236,
         102930,
         236,
         "Manhattan",
         "Upper East Side North",
         "Yellow Zone"
        ],
        [
         237,
         121281,
         237,
         "Manhattan",
         "Upper East Side South",
         "Yellow Zone"
        ],
        [
         239,
         73739,
         239,
         "Manhattan",
         "Upper West Side South",
         "Yellow Zone"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PULocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_trips",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "LocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Borough",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Zone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "service_zone",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use 'display()' or return a pandas DataFrame for 'pretty' output\n",
    "display(top10_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "847abfd1-7424-43c0-976e-5c615736a56b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PULocationID</th><th>average_profit</th><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr></thead><tbody><tr><td>10</td><td>106.87455960856855</td><td>10</td><td>Queens</td><td>Baisley Park</td><td>Boro Zone</td></tr><tr><td>15</td><td>373.64352610622007</td><td>15</td><td>Queens</td><td>Bay Terrace/Fort Totten</td><td>Boro Zone</td></tr><tr><td>59</td><td>36.84437137879828</td><td>59</td><td>Bronx</td><td>Crotona Park</td><td>Boro Zone</td></tr><tr><td>81</td><td>35.018824815920645</td><td>81</td><td>Bronx</td><td>Eastchester</td><td>Boro Zone</td></tr><tr><td>89</td><td>34.99531722605364</td><td>89</td><td>Brooklyn</td><td>Flatbush/Ditmas Park</td><td>Boro Zone</td></tr><tr><td>101</td><td>48.41059594606823</td><td>101</td><td>Queens</td><td>Glen Oaks</td><td>Boro Zone</td></tr><tr><td>115</td><td>38.65</td><td>115</td><td>Staten Island</td><td>Grymes Hill/Clifton</td><td>Boro Zone</td></tr><tr><td>190</td><td>95.73464655984553</td><td>190</td><td>Brooklyn</td><td>Prospect Park</td><td>Boro Zone</td></tr><tr><td>207</td><td>103.12501378067475</td><td>207</td><td>Queens</td><td>Saint Michaels Cemetery/Woodside</td><td>Boro Zone</td></tr><tr><td>241</td><td>59.39185912313199</td><td>241</td><td>Bronx</td><td>Van Cortlandt Village</td><td>Boro Zone</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         10,
         106.87455960856855,
         10,
         "Queens",
         "Baisley Park",
         "Boro Zone"
        ],
        [
         15,
         373.64352610622007,
         15,
         "Queens",
         "Bay Terrace/Fort Totten",
         "Boro Zone"
        ],
        [
         59,
         36.84437137879828,
         59,
         "Bronx",
         "Crotona Park",
         "Boro Zone"
        ],
        [
         81,
         35.018824815920645,
         81,
         "Bronx",
         "Eastchester",
         "Boro Zone"
        ],
        [
         89,
         34.99531722605364,
         89,
         "Brooklyn",
         "Flatbush/Ditmas Park",
         "Boro Zone"
        ],
        [
         101,
         48.41059594606823,
         101,
         "Queens",
         "Glen Oaks",
         "Boro Zone"
        ],
        [
         115,
         38.65,
         115,
         "Staten Island",
         "Grymes Hill/Clifton",
         "Boro Zone"
        ],
        [
         190,
         95.73464655984553,
         190,
         "Brooklyn",
         "Prospect Park",
         "Boro Zone"
        ],
        [
         207,
         103.12501378067475,
         207,
         "Queens",
         "Saint Michaels Cemetery/Woodside",
         "Boro Zone"
        ],
        [
         241,
         59.39185912313199,
         241,
         "Bronx",
         "Van Cortlandt Village",
         "Boro Zone"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PULocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "average_profit",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "LocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Borough",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Zone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "service_zone",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use 'display()' return a pandas DataFrame for 'pretty' output\n",
    "display(top10_profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90eb7561-5775-4e6a-8317-473f311e4cfe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PULocationID</th><th>total_passengers</th><th>LocationID</th><th>Borough</th><th>Zone</th><th>service_zone</th></tr></thead><tbody><tr><td>48</td><td>105804.0</td><td>48</td><td>Manhattan</td><td>Clinton East</td><td>Yellow Zone</td></tr><tr><td>142</td><td>113689.0</td><td>142</td><td>Manhattan</td><td>Lincoln Square East</td><td>Yellow Zone</td></tr><tr><td>161</td><td>133614.0</td><td>161</td><td>Manhattan</td><td>Midtown Center</td><td>Yellow Zone</td></tr><tr><td>162</td><td>118328.0</td><td>162</td><td>Manhattan</td><td>Midtown East</td><td>Yellow Zone</td></tr><tr><td>170</td><td>122448.0</td><td>170</td><td>Manhattan</td><td>Murray Hill</td><td>Yellow Zone</td></tr><tr><td>186</td><td>135960.0</td><td>186</td><td>Manhattan</td><td>Penn Station/Madison Sq West</td><td>Yellow Zone</td></tr><tr><td>234</td><td>104345.0</td><td>234</td><td>Manhattan</td><td>Union Sq</td><td>Yellow Zone</td></tr><tr><td>236</td><td>142914.0</td><td>236</td><td>Manhattan</td><td>Upper East Side North</td><td>Yellow Zone</td></tr><tr><td>237</td><td>169119.0</td><td>237</td><td>Manhattan</td><td>Upper East Side South</td><td>Yellow Zone</td></tr><tr><td>239</td><td>104464.0</td><td>239</td><td>Manhattan</td><td>Upper West Side South</td><td>Yellow Zone</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         48,
         105804.0,
         48,
         "Manhattan",
         "Clinton East",
         "Yellow Zone"
        ],
        [
         142,
         113689.0,
         142,
         "Manhattan",
         "Lincoln Square East",
         "Yellow Zone"
        ],
        [
         161,
         133614.0,
         161,
         "Manhattan",
         "Midtown Center",
         "Yellow Zone"
        ],
        [
         162,
         118328.0,
         162,
         "Manhattan",
         "Midtown East",
         "Yellow Zone"
        ],
        [
         170,
         122448.0,
         170,
         "Manhattan",
         "Murray Hill",
         "Yellow Zone"
        ],
        [
         186,
         135960.0,
         186,
         "Manhattan",
         "Penn Station/Madison Sq West",
         "Yellow Zone"
        ],
        [
         234,
         104345.0,
         234,
         "Manhattan",
         "Union Sq",
         "Yellow Zone"
        ],
        [
         236,
         142914.0,
         236,
         "Manhattan",
         "Upper East Side North",
         "Yellow Zone"
        ],
        [
         237,
         169119.0,
         237,
         "Manhattan",
         "Upper East Side South",
         "Yellow Zone"
        ],
        [
         239,
         104464.0,
         239,
         "Manhattan",
         "Upper West Side South",
         "Yellow Zone"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PULocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_passengers",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "LocationID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Borough",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Zone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "service_zone",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use 'display()' or return a pandas DataFrame for 'pretty' output\n",
    "display(top10_passenger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b950c5e-b7fd-405e-a0ba-0fe9c2752678",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 4 - Record the pipeline's execution time\n",
    "\n",
    "Record the execution time of:\n",
    "\n",
    "1. the whole pipeline\n",
    "2. the whole pipeline except task 1.2\n",
    "\n",
    "on the two tables below, for all dataset sizes: `'S'`, `'M'`, `'L'`, `'XL'`, `'XXL'`, and data formats: `parquet` and `delta`.\n",
    "\n",
    "Analyse the resulting execution times and comment on the effect of dataset size, dataset format and task complexity (with and without task 1.2) on pipeline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e68e8c-4de9-4e04-9de0-f36e24b10f7a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n    Trips dataset loaded!\n    ---\n      Size: XXL\n      Format: delta\n      Tables loaded: /FileStore/tables/taxi/delta/taxi-XXL-delta/\n      Number of trips (dataset rows): 132,396,785\n    \n"
     ]
    }
   ],
   "source": [
    "# CHANGE the value of the following arguments to record the pipeline execution times for increasing dataset sizes\n",
    "SIZE = 'XXL'\n",
    "DATA_FORMAT = 'delta'\n",
    "WITH_TASK_12 = False\n",
    "\n",
    "# Load trips dataset\n",
    "trips = init_trips(SIZE, DATA_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68681494-9d89-4706-908d-c5545444e8ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[DataFrame[PULocationID: bigint, total_trips: bigint, LocationID: bigint, Borough: string, Zone: string, service_zone: string],\n",
       " DataFrame[PULocationID: bigint, average_profit: double, LocationID: bigint, Borough: string, Zone: string, service_zone: string],\n",
       " DataFrame[PULocationID: bigint, total_passengers: double, LocationID: bigint, Borough: string, Zone: string, service_zone: string]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run and record the resulting execution time shown by databricks (on the cell footer)\n",
    "\n",
    "# IMPORTANT: this function calls all task functions in order of occurrence. For this code to run without errors, you have to load into memory all of the previous task-specific functions, even if you haven't implemented these yet.\n",
    "pipeline(trips, with_task_12 = WITH_TASK_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08018100-ac87-4801-94fc-c9fec3dc6a66",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Table 1. Pipeline performance for `parquet` format._\n",
    "\n",
    "| metric                      | S    | M    | L    | XL   | XXL  |\n",
    "|-----------------------------|------|------|------|------|------|\n",
    "| rows (M)                    |  2.898033 |  15.571166 |  41.953716 |  90.443069 |  132.396785 |\n",
    "| execution time   (w/o 1.2)  | 0.36 sec | 0.26 sec | 0.35 sec | 0.33 sec | 0.27 sec |\n",
    "| execution time              | 3.20 sec | 11.18 sec | 27.66 sec | 31.32 sec | 29.98 sec |\n",
    "| sec / 1M records (w/o 1.2)  | 0.124  | 0.017  | 0.008  | 0.004  | 0.002 |\n",
    "| sec / 1M records            | 1.104  | 0.718  | 0.659  | 0.346  | 0.226  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e565c658-ba51-45cc-a617-227d6befb6dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Table 2. Pipeline performance for `delta` format._\n",
    "\n",
    "| metric                      | S    | M    | L    | XL   | XXL  |\n",
    "|-----------------------------|------|------|------|------|------|\n",
    "| rows (M)                    |  2.898033 |  15.571166\t |  41.953716 |  90.443069 |  132.396785 |\n",
    "| execution time   (w/o 1.2)  | 0.30 sec | 0.34 sec | 0.27 sec | 0.30 sec | 0.25 sec |\n",
    "| execution time              | 3.54 sec | 4.97 sec | 7.22 sec | 14.88 sec | 19.89 sec |\n",
    "| sec / 1M records (w/o 1.2)  | 0.104  | 0.022  | 0.006  | 0.003  | 0.002  |\n",
    "| sec / 1M records            | 1.222  | 0.319  | 0.172  | 0.165  | 0.150  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a1cb28e-83e6-4761-a6be-5a0c9496bdf6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Report\n",
    "In analyzing the performance of the above PySpark pipeline we can see that as we progress from smaller ('S') to larger ('XXL') dataset sizes, there's a noticeable increase in execution time across both Parquet and Delta formats. This trend, while expected, is not entirely linear, illustrating how Spark's distributed processing capably handles larger datasets, albeit with increasing overhead. When comparing data formats, it's evident that each possesses unique efficiencies and costs. For instance, while Delta format may excel in handling updates and merges, it can incur greater overhead in other operations compared to Parquet, suggesting a trade-off based on the specific requirements of the task at hand.\n",
    "\n",
    "Another crucial aspect is task complexity, particularly evident in the increased execution times observed when incorporating Task 1.2, which involves outlier removal using the modified Z-score method. This task adds computational complexity, necessitating additional data processing for statistical calculations, thereby extending the total processing time. Additionally, the 'sec / 1M records' metric serves as a useful indicator of the pipeline's scalability and efficiency, with lower values signifying better performance as data volume increases. "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CSC8101-spark-coursework",
   "widgets": {}
  },
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
